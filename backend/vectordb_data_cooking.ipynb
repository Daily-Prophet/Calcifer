{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd072976-53e9-4dc6-87f1-9adb2a37a365",
   "metadata": {},
   "source": [
    "# QA over Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aea8b60-e57a-4e0a-8dee-e4389904107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic openai keys\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import openai\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "openai.api_type = os.environ[\"OPENAI_API_TYPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5e45a1-9797-4a60-9bed-7320905d8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split docs to token chunks\n",
    "\n",
    "# from langchain.text_splitter import TokenTextSplitter\n",
    "# from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "# chunk_size = 200\n",
    "# chunk_overlap = 40\n",
    "\n",
    "# source_file_path = \"./data/document.md\"\n",
    "# loader = UnstructuredMarkdownLoader(\n",
    "#     source_file_path,\n",
    "#     mode=\"elements\",\n",
    "#     strategy=\"fast\",\n",
    "# )\n",
    "# raw_markdown_docs = loader.load()\n",
    "\n",
    "\n",
    "# token_spliter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "# doc_chunks = token_spliter.split_documents(raw_markdown_docs)\n",
    "\n",
    "# print(\n",
    "#     f\"chunk_size: {chunk_size}\\n\\\n",
    "# chunk_overlap: {chunk_overlap}\\n\\n\\\n",
    "# result chunks count: {len(doc_chunks)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca88f67d-e856-45ce-952a-294448228821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "csvLoader = CSVLoader(file_path='./data/recentIncidents.csv', encoding='utf8')\n",
    "raw_incidents_table = csvLoader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b473d7-dfbf-49c7-af79-578d03247fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split docs to header chunks\n",
    "# config chunk_size & chunk_overlap need to tune in the following debugging\n",
    "\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "import markdown\n",
    "\n",
    "with open('./data/document.md', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "doc_chunks = markdown_splitter.split_text(text)\n",
    "len(doc_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d42f249-e4be-4023-83c7-4d541ae6ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append csv into md\n",
    "doc_chunks_contents = [doc.page_content for doc in doc_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f8b939-122e-46d3-af20-4a9c8806cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma vectordb successfully created, its collection count: 1467\n",
      "page_content=\"ID: 381623065\\nTitle: Online: GCC High | Leidos | Unable to download Teams Attendance\\nScenario-Type: Missing Report\\nScenario-SubType: NoReportInTab\\nTags: \\nScenario-Describe【role-env-meettype-scenario】: Organizer couldn't see any attendance report\\nMitigate-Category: Bug(NeedCodeFix)\\nMitigate-Rootcause: Ignore tenant id when request report\\nAction: FE - Fix the invalid request url format\\nMeetingType: \\nEnv: GCC\\nCodeChange: Yes/Done\\nDays: 34.31\\nBack forth possible reason: Yes, GCC data is another db. gcc data need access. support provide wrong har/take long time.\" metadata={'row': 28, 'source': './data/recentIncidents.csv'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Chroma.persist of <langchain.vectorstores.chroma.Chroma object at 0x000001FB75B7B890>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save chunks as vector into db\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"./chroma/\"\n",
    "embeddings = OpenAIEmbeddings(deployment=\"embedding\", chunk_size=16)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=raw_incidents_table,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory,\n",
    ")\n",
    "\n",
    "vectorstore.add_texts(texts = doc_chunks_contents)\n",
    "\n",
    "print(\n",
    "    f\"Chroma vectordb successfully created, its collection count: {vectorstore._collection.count()}\"\n",
    ")\n",
    "\n",
    "# test the vectordb query function\n",
    "test_question = \"Does the gcc tenant support co-organizer attendace report?\"\n",
    "res_docs = vectorstore.similarity_search(test_question, k=5)\n",
    "print(res_docs[0])\n",
    "\n",
    "# save again, this is not necessary, due to we haven't change db after init\n",
    "vectorstore.persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459d2e7f-fc2c-4bc9-b67e-097511df1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n"
     ]
    }
   ],
   "source": [
    "# load the exist local vectorstore\n",
    "persist_directory = \"./chroma/\"\n",
    "embeddings = OpenAIEmbeddings(deployment=\"embedding\", chunk_size=16)\n",
    "local_vectordb = Chroma(\n",
    "    embedding_function=embeddings, persist_directory=persist_directory\n",
    ")\n",
    "print(local_vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49adb5cb-7208-4a63-b173-516a309259b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load llm\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt35-16k\", temperature=0.8)\n",
    "llm.predict(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed4aa3f-7dd4-407c-89c0-1f16c540bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e74406-5b4a-4eb2-a07c-f2101fec8e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the attendance report does support GCCH co-organizers. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "# run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "question = \"Does attendance report support GCCH co-organizer?\"\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=local_vectordb.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 5}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef02ca9-681f-4fb6-8b94-7a1e458ea003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Does attendance report support GCCH co-organizer?',\n",
       " 'result': 'Yes, the attendance report does support GCCH co-organizers. Thanks for asking!',\n",
       " 'source_documents': [Document(page_content=\"'t see entrance for meeting created by outlook/mailbox  |Task 3134411: Enhance support attendance report for co-organizer set through outlook Co-organizer can view/download attendance report same as organizer|\\n| Meeting policy  \", metadata={'category': 'NarrativeText', 'file_directory': '.', 'filename': 'customerescalation.md', 'filetype': 'text/markdown', 'page_number': 1, 'source': './customerescalation.md'}),\n",
       "  Document(page_content=\"ID: 384019674\\nTitle: Online: GCCH | Oshkosh Corporation - oskgovus | Issue: Users are unable to download attendance reports.\\nScenario-Type: Missing Report\\nScenario-SubType: NoReportInTab\\nTags: \\nScenario-Describe【role-env-meettype-scenario】: Organizer couldn't see any attendance report\\nMitigate-Category: Bug(NeedCodeFix)\\nMitigate-Rootcause: Ignore tenant id when request report\\nAction: FE - Fix the invalid request url format\\nMeetingType: \\nEnv: GCC\\nCodeChange: Yes/Done\\nDays: 15.3\\nBack forth possible reason: \", metadata={'row': 29, 'source': './data/recentIncidents.csv'}),\n",
       "  Document(page_content=\"ID: 390137157\\nTitle: Online: Co-organizer can't access meeting attendance report\\nScenario-Type: Missing Report\\nScenario-SubType: mailbox\\nTags: Coorganizer, mailbox\\nScenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\\nMitigate-Category: Limitation(NeedEnhancement)\\nMitigate-Rootcause: Co-org could not see AR - shared mailbox\\nAction: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\\nMeetingType: \\nEnv: \\nCodeChange: \\nDays: 0.5\\nBack forth possible reason: \", metadata={'row': 21, 'source': './data/recentIncidents.csv'}),\n",
       "  Document(page_content=\"ID: 390137157\\nTitle: Online: Co-organizer can't access meeting attendance report\\nScenario-Type: Missing Report\\nScenario-SubType: mailbox\\nTags: Coorganizer, mailbox\\nScenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\\nMitigate-Category: Limitation(NeedEnhancement)\\nMitigate-Rootcause: Co-org could not see AR - shared mailbox\\nAction: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\\nMeetingType: \\nEnv: \\nCodeChange: \\nDays: 0.5\\nBack forth possible reason: \", metadata={'row': 21, 'source': './data/recentIncidents.csv'}),\n",
       "  Document(page_content=\"ID: 390137157\\nTitle: Online: Co-organizer can't access meeting attendance report\\nScenario-Type: Missing Report\\nScenario-SubType: mailbox\\nTags: Coorganizer, mailbox\\nScenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\\nMitigate-Category: Limitation(NeedEnhancement)\\nMitigate-Rootcause: Co-org could not see AR - shared mailbox\\nAction: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\\nMeetingType: \\nEnv: \\nCodeChange: \\nDays: 0.5\\nBack forth possible reason: \", metadata={'row': 21, 'source': './data/recentIncidents.csv'})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc210b10-6490-4e79-9439-ad21faa71b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved source_documents count: 5\n",
      "'t see entrance for meeting created by outlook/mailbox  |Task 3134411: Enhance support attendance report for co-organizer set through outlook Co-organizer can view/download attendance report same as organizer|\n",
      "| Meeting policy  \n",
      "\n",
      "ID: 384019674\n",
      "Title: Online: GCCH | Oshkosh Corporation - oskgovus | Issue: Users are unable to download attendance reports.\n",
      "Scenario-Type: Missing Report\n",
      "Scenario-SubType: NoReportInTab\n",
      "Tags: \n",
      "Scenario-Describe【role-env-meettype-scenario】: Organizer couldn't see any attendance report\n",
      "Mitigate-Category: Bug(NeedCodeFix)\n",
      "Mitigate-Rootcause: Ignore tenant id when request report\n",
      "Action: FE - Fix the invalid request url format\n",
      "MeetingType: \n",
      "Env: GCC\n",
      "CodeChange: Yes/Done\n",
      "Days: 15.3\n",
      "Back forth possible reason: \n",
      "\n",
      "ID: 390137157\n",
      "Title: Online: Co-organizer can't access meeting attendance report\n",
      "Scenario-Type: Missing Report\n",
      "Scenario-SubType: mailbox\n",
      "Tags: Coorganizer, mailbox\n",
      "Scenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\n",
      "Mitigate-Category: Limitation(NeedEnhancement)\n",
      "Mitigate-Rootcause: Co-org could not see AR - shared mailbox\n",
      "Action: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\n",
      "MeetingType: \n",
      "Env: \n",
      "CodeChange: \n",
      "Days: 0.5\n",
      "Back forth possible reason: \n",
      "\n",
      "ID: 390137157\n",
      "Title: Online: Co-organizer can't access meeting attendance report\n",
      "Scenario-Type: Missing Report\n",
      "Scenario-SubType: mailbox\n",
      "Tags: Coorganizer, mailbox\n",
      "Scenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\n",
      "Mitigate-Category: Limitation(NeedEnhancement)\n",
      "Mitigate-Rootcause: Co-org could not see AR - shared mailbox\n",
      "Action: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\n",
      "MeetingType: \n",
      "Env: \n",
      "CodeChange: \n",
      "Days: 0.5\n",
      "Back forth possible reason: \n",
      "\n",
      "ID: 390137157\n",
      "Title: Online: Co-organizer can't access meeting attendance report\n",
      "Scenario-Type: Missing Report\n",
      "Scenario-SubType: mailbox\n",
      "Tags: Coorganizer, mailbox\n",
      "Scenario-Describe【role-env-meettype-scenario】: Cor-organizer couldn't see attendance report for meeting created by shared mailbox\n",
      "Mitigate-Category: Limitation(NeedEnhancement)\n",
      "Mitigate-Rootcause: Co-org could not see AR - shared mailbox\n",
      "Action: BE - figure out reason of mailbox+ set cororg will work? + co-org solution in chatservice\n",
      "MeetingType: \n",
      "Env: \n",
      "CodeChange: \n",
      "Days: 0.5\n",
      "Back forth possible reason: \n"
     ]
    }
   ],
   "source": [
    "print(\"retrieved source_documents count:\", len(result[\"source_documents\"]))\n",
    "print('\\n\\n'.join([doc.page_content for doc in result[\"source_documents\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76be5d82-843f-45b4-8156-d720baf5f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are five cases or reasons for a missing report. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"How many cases or reasons for missing report?\"})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebeb2e3-e810-489c-9a24-a2b4927d9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved source_documents count: 5\n",
      "Missing Reports\n",
      "\n",
      "Missing Reports\n",
      "\n",
      "Missing Reports\n",
      "\n",
      "There are five key scenarios when do the triage of the issue. Missing entrance, Missing Reports, Download failed, Missing Data, Wrong Report Content\n",
      "\n",
      "Missing entrance, Missing Reports, Download failed, Missing Data, Wrong Report Content\n"
     ]
    }
   ],
   "source": [
    "print(\"retrieved source_documents count:\", len(result[\"source_documents\"]))\n",
    "print('\\n\\n'.join([doc.page_content for doc in result[\"source_documents\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a434870-ff94-4c9e-859e-456976393a67",
   "metadata": {},
   "source": [
    "# Private domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb770dab-0650-45b1-8fb8-8bd1488f023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "local_path = (\"C:/Users/yanfu/Downloads/ggml-gpt4all-j-v1.3-groovy.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbc94ed-a3dc-4f2c-a105-b34ece235119",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import gpt4all python package. Please install it with `pip install gpt4all`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Project\\Calcifer\\backend\\devenv\\Lib\\site-packages\\langchain\\llms\\gpt4all.py:129\u001b[0m, in \u001b[0;36mGPT4All.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt4all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT4All \u001b[38;5;28;01mas\u001b[39;00m GPT4AllModel\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gpt4all'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [StreamingStdOutCallbackHandler()]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Verbose is required to pass to the callback manager\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mGPT4All\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mAnswer: Let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms think step by step.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(template\u001b[38;5;241m=\u001b[39mtemplate, input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\Project\\Calcifer\\backend\\devenv\\Lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\Project\\Calcifer\\backend\\devenv\\Lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Project\\Calcifer\\backend\\devenv\\Lib\\site-packages\\pydantic\\main.py:1102\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Project\\Calcifer\\backend\\devenv\\Lib\\site-packages\\langchain\\llms\\gpt4all.py:131\u001b[0m, in \u001b[0;36mGPT4All.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt4all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT4All \u001b[38;5;28;01mas\u001b[39;00m GPT4AllModel\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import gpt4all python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install gpt4all`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m     )\n\u001b[0;32m    136\u001b[0m full_path \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    137\u001b[0m model_path, delimiter, model_name \u001b[38;5;241m=\u001b[39m full_path\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import gpt4all python package. Please install it with `pip install gpt4all`."
     ]
    }
   ],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# Verbose is required to pass to the callback manager\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730f43b-770b-4a34-b282-72e021b10e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03140a59-8d93-4984-8126-1a72c4090546",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \\\n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "Context: \n",
    "organizer restart the client and check attendance report, tracked by Task 3183235: Standard solution to enhance the support attendance report for coorganizer. [Limitation] Didn't support coorganizer in GCCH/DOD env, due to\n",
    "\n",
    "] The coorganizer thread property is overrided. workaround: 1. Remove the co-organzier then save 2. Add the co-organzier back then save 3. co-organizer restart the client and check attendance report, tracked by Task 3183235: Standard solution to enhance the support attendance report for coorganizer. [Limitation] Didn't support coorganizer in GCCH/DOD env, due to couldn't set coorganizerid thread property successfully.\n",
    "| Customer could always see the entrance of in meeting attendance reports    | inmeetingreport || [ByDesign]Those tenants can always use in-meeting report feature regardless of the policy value, tenant list please see [Reference]   |||\n",
    "| Customer couldn't find channel meeting's report download chiclet from its post comments    | channelmeetingchiclet || [Limitation]Channel 2.0 team no longer provides report control messages after\n",
    "\n",
    "'t see entrance for meeting created by outlook/mailbox  |Task 3134411: Enhance support attendance report for co-organizer set through outlook Co-organizer can view/download attendance report same as organizer|\n",
    "| Meeting policy  \n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain.prompt = prompt2\n",
    "\n",
    "# llm_chain2 = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ab9ef-c577-429c-8fe0-3b95d7feb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Does the gcc tenant support co-organizer attendace report?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4b625-4585-4567-a610-a58ad3b022c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
